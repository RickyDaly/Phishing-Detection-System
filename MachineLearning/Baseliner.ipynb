{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c697fda6-88d7-4a00-b93b-cc0bab3349b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Machine Learning Models\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from lightgbm import LGBMClassifier, plot_importance\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a20ce8-e746-4d04-b645-d617ac139cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL\n",
    "df1 = pd.read_csv('url_features.csv').sort_values(by='url')\n",
    "df1 = pd.get_dummies(df1, columns=['tld_type'], prefix='tld')\n",
    "X1 = df1.drop(['url','label'], axis=1)\n",
    "y1 = df1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc136e98-e13c-4cf3-adbb-4276f532a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTML\n",
    "df2 = pd.read_csv('new_html_features.csv').sort_values(by='url')\n",
    "X2 = df2.drop(['label', 'url'], axis=1)\n",
    "y2 = df2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eede6be-157c-4ca5-b842-c6a07ae50eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOM\n",
    "df3 = pd.read_csv('dom_features_output.csv').sort_values(by='url')\n",
    "X3 = df3.drop(['url','label'], axis=1)\n",
    "y3 = df3['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8113db9d-4604-45e4-abc9-01d0de9c8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined\n",
    "df4 = pd.read_csv('combined_features.csv').sort_values(by='url')\n",
    "df4 = pd.get_dummies(df4, columns=['tld_type'], prefix='tld')\n",
    "X4 = df4.drop(['url','label'], axis=1)\n",
    "y4 = df4['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c491fdbe-ce81-496f-b566-a3cfe1554a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, stratify=y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d729db-5d97-4a3a-9ba3-12eeecb6dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, stratify=y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b88fc50-caae-40cb-b67d-46b7a8d800ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, stratify=y3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe901e7-9c02-44d3-8999-91e77b9b88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, stratify=y4, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0653c64e-f72d-40eb-87f6-ae1c59d6d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier( random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier( random_state=42),\n",
    "    \"K-Nearest Neighbor\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier( random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f20704-fc4a-4e62-8c60-aff0ce32d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== URL =====\n",
      "\n",
      "XGBoost - 5-Fold CV on 80% Training Set\n",
      "\n",
      "LightGBM - 5-Fold CV on 80% Training Set\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 446124, number of used features: 228\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466339\n",
      "[LightGBM] [Info] Start training from score -3.466339\n",
      "[LightGBM] [Info] Number of positive: 13512, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 782\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 229\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030287 -> initscore=-3.466265\n",
      "[LightGBM] [Info] Start training from score -3.466265\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 755\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 222\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 225\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 16889, number of negative: 540767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 788\n",
      "[LightGBM] [Info] Number of data points in the train set: 557656, number of used features: 239\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030286 -> initscore=-3.466326\n",
      "[LightGBM] [Info] Start training from score -3.466326\n",
      "\n",
      "Random Forest - 5-Fold CV on 80% Training Set\n",
      "\n",
      "K-Nearest Neighbor - 5-Fold CV on 80% Training Set\n",
      "\n",
      "Decision Tree - 5-Fold CV on 80% Training Set\n",
      "\n",
      "======================================================================\n",
      "XGBoost | DATASET: URL\n",
      "CV Average Accuracy     : 0.9763\n",
      "CV Avg Precision        : 0.9724\n",
      "CV Avg Recall           : 0.9763\n",
      "CV Avg F1-Score         : 0.9727\n",
      "Average Training Time   : 6.8166 s\n",
      "Average Prediction Time : 0.2420 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.980634  0.995209  0.987868  108153.400000\n",
      "1              0.707590  0.370715  0.486444    3377.800000\n",
      "accuracy       0.976295  0.976295  0.976295       0.976295\n",
      "macro avg      0.844112  0.682962  0.737156  111531.200000\n",
      "weighted avg   0.972365  0.976295  0.972682  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9763\n",
      "Test Set Confusion Matrix:\n",
      "[[134441    752]\n",
      " [  2546   1676]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    135193\n",
      "           1       0.69      0.40      0.50      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.84      0.70      0.75    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LightGBM | DATASET: URL\n",
      "CV Average Accuracy     : 0.9762\n",
      "CV Avg Precision        : 0.9722\n",
      "CV Avg Recall           : 0.9762\n",
      "CV Avg F1-Score         : 0.9725\n",
      "Average Training Time   : 2.1987 s\n",
      "Average Prediction Time : 0.3109 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.980412  0.995360  0.987830  108153.400000\n",
      "1              0.709840  0.363254  0.480489    3377.800000\n",
      "accuracy       0.976217  0.976217  0.976217       0.976217\n",
      "macro avg      0.845126  0.679307  0.734159  111531.200000\n",
      "weighted avg   0.972218  0.976217  0.972464  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9764\n",
      "Test Set Confusion Matrix:\n",
      "[[134563    630]\n",
      " [  2661   1561]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.71      0.37      0.49      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.85      0.68      0.74    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Random Forest | DATASET: URL\n",
      "CV Average Accuracy     : 0.9768\n",
      "CV Avg Precision        : 0.9736\n",
      "CV Avg Recall           : 0.9768\n",
      "CV Avg F1-Score         : 0.9744\n",
      "Average Training Time   : 204.4657 s\n",
      "Average Prediction Time : 3.5361 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.982665  0.993624  0.988114  108153.400000\n",
      "1              0.682722  0.438747  0.534076    3377.800000\n",
      "accuracy       0.976819  0.976819  0.976819       0.976819\n",
      "macro avg      0.832694  0.716185  0.761095  111531.200000\n",
      "weighted avg   0.973581  0.976819  0.974363  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9770\n",
      "Test Set Confusion Matrix:\n",
      "[[134289    904]\n",
      " [  2299   1923]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    135193\n",
      "           1       0.68      0.46      0.55      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.83      0.72      0.77    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "K-Nearest Neighbor | DATASET: URL\n",
      "CV Average Accuracy     : 0.9746\n",
      "CV Avg Precision        : 0.9708\n",
      "CV Avg Recall           : 0.9746\n",
      "CV Avg F1-Score         : 0.9720\n",
      "Average Training Time   : 2.1341 s\n",
      "Average Prediction Time : 201.9667 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.981721  0.992244  0.986954  108153.400000\n",
      "1              0.621702  0.408431  0.492825    3377.800000\n",
      "accuracy       0.974563  0.974563  0.974563       0.974563\n",
      "macro avg      0.801712  0.700337  0.739890  111531.200000\n",
      "weighted avg   0.970817  0.974563  0.971989  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9744\n",
      "Test Set Confusion Matrix:\n",
      "[[134118   1075]\n",
      " [  2491   1731]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    135193\n",
      "           1       0.62      0.41      0.49      4222\n",
      "\n",
      "    accuracy                           0.97    139415\n",
      "   macro avg       0.80      0.70      0.74    139415\n",
      "weighted avg       0.97      0.97      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Decision Tree | DATASET: URL\n",
      "CV Average Accuracy     : 0.9765\n",
      "CV Avg Precision        : 0.9733\n",
      "CV Avg Recall           : 0.9765\n",
      "CV Avg F1-Score         : 0.9741\n",
      "Average Training Time   : 105.4433 s\n",
      "Average Prediction Time : 0.3719 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.982675  0.993284  0.987951  108153.400000\n",
      "1              0.671579  0.439279  0.531041    3377.800000\n",
      "accuracy       0.976505  0.976505  0.976505       0.976505\n",
      "macro avg      0.827127  0.716281  0.759496  111531.200000\n",
      "weighted avg   0.973253  0.976505  0.974113  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9768\n",
      "Test Set Confusion Matrix:\n",
      "[[134283    910]\n",
      " [  2319   1903]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    135193\n",
      "           1       0.68      0.45      0.54      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.83      0.72      0.76    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "\n",
      "===== HTML =====\n",
      "\n",
      "XGBoost - 5-Fold CV on 80% Training Set\n",
      "\n",
      "LightGBM - 5-Fold CV on 80% Training Set\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6018\n",
      "[LightGBM] [Info] Number of data points in the train set: 446124, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466339\n",
      "[LightGBM] [Info] Start training from score -3.466339\n",
      "[LightGBM] [Info] Number of positive: 13512, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6042\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030287 -> initscore=-3.466265\n",
      "[LightGBM] [Info] Start training from score -3.466265\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6039\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6115\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6038\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 16889, number of negative: 540767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6083\n",
      "[LightGBM] [Info] Number of data points in the train set: 557656, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030286 -> initscore=-3.466326\n",
      "[LightGBM] [Info] Start training from score -3.466326\n",
      "\n",
      "Random Forest - 5-Fold CV on 80% Training Set\n",
      "\n",
      "K-Nearest Neighbor - 5-Fold CV on 80% Training Set\n",
      "\n",
      "Decision Tree - 5-Fold CV on 80% Training Set\n",
      "\n",
      "======================================================================\n",
      "XGBoost | DATASET: HTML\n",
      "CV Average Accuracy     : 0.9809\n",
      "CV Avg Precision        : 0.9789\n",
      "CV Avg Recall           : 0.9809\n",
      "CV Avg F1-Score         : 0.9781\n",
      "Average Training Time   : 1.9202 s\n",
      "Average Prediction Time : 0.0650 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.983213  0.997309  0.990211  108153.400000\n",
      "1              0.840655  0.454794  0.590173    3377.800000\n",
      "accuracy       0.980879  0.980879  0.980879       0.980879\n",
      "macro avg      0.911934  0.726052  0.790192  111531.200000\n",
      "weighted avg   0.978896  0.980879  0.978096  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9813\n",
      "Test Set Confusion Matrix:\n",
      "[[134854    339]\n",
      " [  2271   1951]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.85      0.46      0.60      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.92      0.73      0.79    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LightGBM | DATASET: HTML\n",
      "CV Average Accuracy     : 0.9806\n",
      "CV Avg Precision        : 0.9787\n",
      "CV Avg Recall           : 0.9806\n",
      "CV Avg F1-Score         : 0.9774\n",
      "Average Training Time   : 1.6843 s\n",
      "Average Prediction Time : 0.1161 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.982430  0.997822  0.990066  108153.400000\n",
      "1              0.859971  0.428623  0.572076    3377.800000\n",
      "accuracy       0.980583  0.980583  0.980583       0.980583\n",
      "macro avg      0.921200  0.713222  0.781071  111531.200000\n",
      "weighted avg   0.978721  0.980583  0.977407  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9807\n",
      "Test Set Confusion Matrix:\n",
      "[[134881    312]\n",
      " [  2385   1837]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.85      0.44      0.58      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.92      0.72      0.78    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Random Forest | DATASET: HTML\n",
      "CV Average Accuracy     : 0.9820\n",
      "CV Avg Precision        : 0.9802\n",
      "CV Avg Recall           : 0.9820\n",
      "CV Avg F1-Score         : 0.9802\n",
      "Average Training Time   : 92.6482 s\n",
      "Average Prediction Time : 2.0274 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.985480  0.996137  0.990780  108153.400000\n",
      "1              0.810858  0.530050  0.640994    3377.800000\n",
      "accuracy       0.982021  0.982021  0.982021       0.982021\n",
      "macro avg      0.898169  0.763093  0.815887  111531.200000\n",
      "weighted avg   0.980191  0.982021  0.980186  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9823\n",
      "Test Set Confusion Matrix:\n",
      "[[134675    518]\n",
      " [  1947   2275]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    135193\n",
      "           1       0.81      0.54      0.65      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.90      0.77      0.82    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "K-Nearest Neighbor | DATASET: HTML\n",
      "CV Average Accuracy     : 0.9784\n",
      "CV Avg Precision        : 0.9774\n",
      "CV Avg Recall           : 0.9784\n",
      "CV Avg F1-Score         : 0.9777\n",
      "Average Training Time   : 0.2737 s\n",
      "Average Prediction Time : 56.6175 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.987096  0.990636  0.988859  108153.400000\n",
      "1              0.668305  0.585174  0.620490    3377.800000\n",
      "accuracy       0.978356  0.978356  0.978356       0.978356\n",
      "macro avg      0.827700  0.787905  0.804674  111531.200000\n",
      "weighted avg   0.977441  0.978356  0.977703  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9783\n",
      "Test Set Confusion Matrix:\n",
      "[[133911   1282]\n",
      " [  1737   2485]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    135193\n",
      "           1       0.66      0.59      0.62      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.82      0.79      0.81    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Decision Tree | DATASET: HTML\n",
      "CV Average Accuracy     : 0.9804\n",
      "CV Avg Precision        : 0.9783\n",
      "CV Avg Recall           : 0.9804\n",
      "CV Avg F1-Score         : 0.9787\n",
      "Average Training Time   : 15.7069 s\n",
      "Average Prediction Time : 0.0892 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.985417  0.994511  0.989943  108153.400000\n",
      "1              0.750613  0.528747  0.620316    3377.800000\n",
      "accuracy       0.980405  0.980405  0.980405       0.980405\n",
      "macro avg      0.868015  0.761629  0.805129  111531.200000\n",
      "weighted avg   0.978306  0.980405  0.978749  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9808\n",
      "Test Set Confusion Matrix:\n",
      "[[134458    735]\n",
      " [  1942   2280]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    135193\n",
      "           1       0.76      0.54      0.63      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.87      0.77      0.81    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "\n",
      "===== DOM =====\n",
      "\n",
      "XGBoost - 5-Fold CV on 80% Training Set\n",
      "\n",
      "LightGBM - 5-Fold CV on 80% Training Set\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 446124, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466339\n",
      "[LightGBM] [Info] Start training from score -3.466339\n",
      "[LightGBM] [Info] Number of positive: 13512, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.430705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030287 -> initscore=-3.466265\n",
      "[LightGBM] [Info] Start training from score -3.466265\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.734875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 16889, number of negative: 540767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.526156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 557656, number of used features: 300\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030286 -> initscore=-3.466326\n",
      "[LightGBM] [Info] Start training from score -3.466326\n",
      "\n",
      "Random Forest - 5-Fold CV on 80% Training Set\n",
      "\n",
      "K-Nearest Neighbor - 5-Fold CV on 80% Training Set\n",
      "\n",
      "Decision Tree - 5-Fold CV on 80% Training Set\n",
      "\n",
      "======================================================================\n",
      "XGBoost | DATASET: DOM\n",
      "CV Average Accuracy     : 0.9763\n",
      "CV Avg Precision        : 0.9723\n",
      "CV Avg Recall           : 0.9763\n",
      "CV Avg F1-Score         : 0.9726\n",
      "Average Training Time   : 48.4963 s\n",
      "Average Prediction Time : 0.1299 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.980546  0.995272  0.987854  108153.400000\n",
      "1              0.708284  0.367755  0.484104    3377.800000\n",
      "accuracy       0.976267  0.976267  0.976267       0.976267\n",
      "macro avg      0.844415  0.681513  0.735979  111531.200000\n",
      "weighted avg   0.972301  0.976267  0.972598  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9764\n",
      "Test Set Confusion Matrix:\n",
      "[[134535    658]\n",
      " [  2636   1586]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.71      0.38      0.49      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.84      0.69      0.74    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LightGBM | DATASET: DOM\n",
      "CV Average Accuracy     : 0.9750\n",
      "CV Avg Precision        : 0.9703\n",
      "CV Avg Recall           : 0.9750\n",
      "CV Avg F1-Score         : 0.9700\n",
      "Average Training Time   : 33.7222 s\n",
      "Average Prediction Time : 0.2857 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.978366  0.996272  0.987238  108153.400000\n",
      "1              0.711975  0.294630  0.416753    3377.800000\n",
      "accuracy       0.975022  0.975022  0.975022       0.975022\n",
      "macro avg      0.845171  0.645451  0.701995  111531.200000\n",
      "weighted avg   0.970298  0.975022  0.969960  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9750\n",
      "Test Set Confusion Matrix:\n",
      "[[134636    557]\n",
      " [  2933   1289]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.70      0.31      0.42      4222\n",
      "\n",
      "    accuracy                           0.97    139415\n",
      "   macro avg       0.84      0.65      0.71    139415\n",
      "weighted avg       0.97      0.97      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Random Forest | DATASET: DOM\n",
      "CV Average Accuracy     : 0.9766\n",
      "CV Avg Precision        : 0.9734\n",
      "CV Avg Recall           : 0.9766\n",
      "CV Avg F1-Score         : 0.9713\n",
      "Average Training Time   : 2134.9750 s\n",
      "Average Prediction Time : 4.0884 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.978488  0.997836  0.988068  108153.400000\n",
      "1              0.811125  0.297591  0.435376    3377.800000\n",
      "accuracy       0.976629  0.976629  0.976629       0.976629\n",
      "macro avg      0.894806  0.647714  0.711722  111531.200000\n",
      "weighted avg   0.973419  0.976629  0.971329  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9769\n",
      "Test Set Confusion Matrix:\n",
      "[[134858    335]\n",
      " [  2889   1333]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.80      0.32      0.45      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.89      0.66      0.72    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "K-Nearest Neighbor | DATASET: DOM\n",
      "CV Average Accuracy     : 0.9756\n",
      "CV Avg Precision        : 0.9725\n",
      "CV Avg Recall           : 0.9756\n",
      "CV Avg F1-Score         : 0.9735\n",
      "Average Training Time   : 0.7744 s\n",
      "Average Prediction Time : 157.9875 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.982965  0.992039  0.987481  108153.400000\n",
      "1              0.638174  0.449524  0.527402    3377.800000\n",
      "accuracy       0.975609  0.975609  0.975609       0.975609\n",
      "macro avg      0.810570  0.720782  0.757442  111531.200000\n",
      "weighted avg   0.972523  0.975609  0.973547  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9758\n",
      "Test Set Confusion Matrix:\n",
      "[[134127   1066]\n",
      " [  2305   1917]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    135193\n",
      "           1       0.64      0.45      0.53      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.81      0.72      0.76    139415\n",
      "weighted avg       0.97      0.98      0.97    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Decision Tree | DATASET: DOM\n",
      "CV Average Accuracy     : 0.9581\n",
      "CV Avg Precision        : 0.9617\n",
      "CV Avg Recall           : 0.9581\n",
      "CV Avg F1-Score         : 0.9598\n",
      "Average Training Time   : 762.4875 s\n",
      "Average Prediction Time : 0.1399 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.981207  0.975446  0.978318  108153.400000\n",
      "1              0.338115  0.401801  0.367199    3377.800000\n",
      "accuracy       0.958073  0.958073  0.958073       0.958073\n",
      "macro avg      0.659661  0.688624  0.672758  111531.200000\n",
      "weighted avg   0.961731  0.958073  0.959810  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9586\n",
      "Test Set Confusion Matrix:\n",
      "[[131917   3276]\n",
      " [  2499   1723]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    135193\n",
      "           1       0.34      0.41      0.37      4222\n",
      "\n",
      "    accuracy                           0.96    139415\n",
      "   macro avg       0.66      0.69      0.68    139415\n",
      "weighted avg       0.96      0.96      0.96    139415\n",
      "\n",
      "\n",
      "\n",
      "===== COMBINED =====\n",
      "\n",
      "XGBoost - 5-Fold CV on 80% Training Set\n",
      "\n",
      "LightGBM - 5-Fold CV on 80% Training Set\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.504589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 80577\n",
      "[LightGBM] [Info] Number of data points in the train set: 446124, number of used features: 561\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466339\n",
      "[LightGBM] [Info] Start training from score -3.466339\n",
      "[LightGBM] [Info] Number of positive: 13512, number of negative: 432613\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.531143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 80582\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 563\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030287 -> initscore=-3.466265\n",
      "[LightGBM] [Info] Start training from score -3.466265\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.500073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 80575\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.482942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 80548\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 545\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 13511, number of negative: 432614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.482258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 80570\n",
      "[LightGBM] [Info] Number of data points in the train set: 446125, number of used features: 559\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030285 -> initscore=-3.466342\n",
      "[LightGBM] [Info] Start training from score -3.466342\n",
      "[LightGBM] [Info] Number of positive: 16889, number of negative: 540767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.604465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 80583\n",
      "[LightGBM] [Info] Number of data points in the train set: 557656, number of used features: 573\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030286 -> initscore=-3.466326\n",
      "[LightGBM] [Info] Start training from score -3.466326\n",
      "\n",
      "Random Forest - 5-Fold CV on 80% Training Set\n",
      "\n",
      "K-Nearest Neighbor - 5-Fold CV on 80% Training Set\n",
      "\n",
      "Decision Tree - 5-Fold CV on 80% Training Set\n",
      "\n",
      "======================================================================\n",
      "XGBoost | DATASET: COMBINED\n",
      "CV Average Accuracy     : 0.9841\n",
      "CV Avg Precision        : 0.9829\n",
      "CV Avg Recall           : 0.9841\n",
      "CV Avg F1-Score         : 0.9832\n",
      "Average Training Time   : 49.1334 s\n",
      "Average Prediction Time : 0.2935 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score       support\n",
      "0              0.988660  0.995027  0.991833  108153.40000\n",
      "1              0.799382  0.634556  0.707466    3377.80000\n",
      "accuracy       0.984110  0.984110  0.984110       0.98411\n",
      "macro avg      0.894021  0.814792  0.849649  111531.20000\n",
      "weighted avg   0.982927  0.984110  0.983221  111531.20000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9846\n",
      "Test Set Confusion Matrix:\n",
      "[[134568    625]\n",
      " [  1519   2703]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    135193\n",
      "           1       0.81      0.64      0.72      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.90      0.82      0.85    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LightGBM | DATASET: COMBINED\n",
      "CV Average Accuracy     : 0.9833\n",
      "CV Avg Precision        : 0.9819\n",
      "CV Avg Recall           : 0.9833\n",
      "CV Avg F1-Score         : 0.9822\n",
      "Average Training Time   : 21.8571 s\n",
      "Average Prediction Time : 0.5131 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.987552  0.995373  0.991447  108153.400000\n",
      "1              0.801686  0.598260  0.685143    3377.800000\n",
      "accuracy       0.983346  0.983346  0.983346       0.983346\n",
      "macro avg      0.894619  0.796816  0.838295  111531.200000\n",
      "weighted avg   0.981923  0.983346  0.982170  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9838\n",
      "Test Set Confusion Matrix:\n",
      "[[134594    599]\n",
      " [  1666   2556]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    135193\n",
      "           1       0.81      0.61      0.69      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.90      0.80      0.84    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Random Forest | DATASET: COMBINED\n",
      "CV Average Accuracy     : 0.9822\n",
      "CV Avg Precision        : 0.9806\n",
      "CV Avg Recall           : 0.9822\n",
      "CV Avg F1-Score         : 0.9798\n",
      "Average Training Time   : 1482.1508 s\n",
      "Average Prediction Time : 3.9405 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.984299  0.997548  0.990879  108153.400000\n",
      "1              0.862000  0.490497  0.625199    3377.800000\n",
      "accuracy       0.982192  0.982192  0.982192       0.982192\n",
      "macro avg      0.923149  0.744022  0.808039  111531.200000\n",
      "weighted avg   0.980595  0.982192  0.979804  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9825\n",
      "Test Set Confusion Matrix:\n",
      "[[134817    376]\n",
      " [  2069   2153]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    135193\n",
      "           1       0.85      0.51      0.64      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.92      0.75      0.81    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "K-Nearest Neighbor | DATASET: COMBINED\n",
      "CV Average Accuracy     : 0.9864\n",
      "CV Avg Precision        : 0.9858\n",
      "CV Avg Recall           : 0.9864\n",
      "CV Avg F1-Score         : 0.9860\n",
      "Average Training Time   : 3.6198 s\n",
      "Average Prediction Time : 338.7617 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.991144  0.994900  0.993019  108153.400000\n",
      "1              0.814163  0.715376  0.761564    3377.800000\n",
      "accuracy       0.986434  0.986434  0.986434       0.986434\n",
      "macro avg      0.902654  0.855138  0.877291  111531.200000\n",
      "weighted avg   0.985784  0.986434  0.986009  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9868\n",
      "Test Set Confusion Matrix:\n",
      "[[134528    665]\n",
      " [  1175   3047]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    135193\n",
      "           1       0.82      0.72      0.77      4222\n",
      "\n",
      "    accuracy                           0.99    139415\n",
      "   macro avg       0.91      0.86      0.88    139415\n",
      "weighted avg       0.99      0.99      0.99    139415\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Decision Tree | DATASET: COMBINED\n",
      "CV Average Accuracy     : 0.9753\n",
      "CV Avg Precision        : 0.9763\n",
      "CV Avg Recall           : 0.9753\n",
      "CV Avg F1-Score         : 0.9757\n",
      "Average Training Time   : 8208.6691 s\n",
      "Average Prediction Time : 0.3781 s\n",
      "\n",
      "Average Classification Report from 5-Fold CV:\n",
      "              precision    recall  f1-score        support\n",
      "0              0.988491  0.985979  0.987233  108153.400000\n",
      "1              0.584871  0.632423  0.607694    3377.800000\n",
      "accuracy       0.975271  0.975271  0.975271       0.975271\n",
      "macro avg      0.786681  0.809201  0.797464  111531.200000\n",
      "weighted avg   0.976267  0.975271  0.975739  111531.200000\n",
      "\n",
      "Test Set Accuracy (20%) : 0.9762\n",
      "Test Set Confusion Matrix:\n",
      "[[133371   1822]\n",
      " [  1502   2720]]\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    135193\n",
      "           1       0.60      0.64      0.62      4222\n",
      "\n",
      "    accuracy                           0.98    139415\n",
      "   macro avg       0.79      0.82      0.80    139415\n",
      "weighted avg       0.98      0.98      0.98    139415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def run_cv_block(X_train, y_train, X_test, y_test, models, dataset_name):\n",
    "    print(f\"\\n\\n===== {dataset_name} =====\")\n",
    "    cv_results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name} - 5-Fold CV on 80% Training Set\")\n",
    "\n",
    "        fold_accuracies = []\n",
    "        fold_precisions = []\n",
    "        fold_recalls = []\n",
    "        fold_f1s = []\n",
    "        fold_reports = []\n",
    "\n",
    "        training_times = []\n",
    "        prediction_times = []\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(X_train, y_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            start_train = time.time()\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            end_train = time.time()\n",
    "\n",
    "            start_pred = time.time()\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            end_pred = time.time()\n",
    "\n",
    "            fold_accuracies.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "            fold_precisions.append(precision_score(y_val_fold, y_val_pred, average='weighted', zero_division=0))\n",
    "            fold_recalls.append(recall_score(y_val_fold, y_val_pred, average='weighted', zero_division=0))\n",
    "            fold_f1s.append(f1_score(y_val_fold, y_val_pred, average='weighted', zero_division=0))\n",
    "\n",
    "            report = classification_report(y_val_fold, y_val_pred, output_dict=True, zero_division=0)\n",
    "            fold_reports.append(pd.DataFrame(report).transpose())\n",
    "\n",
    "            training_times.append(end_train - start_train)\n",
    "            prediction_times.append(end_pred - start_pred)\n",
    "\n",
    "        # Average classification report across folds\n",
    "        avg_report_df = pd.concat(fold_reports).groupby(level=0).mean()\n",
    "\n",
    "        # Final model on all 80% training data\n",
    "        model.fit(X_train, y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "        test_class_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "        cv_results[name] = {\n",
    "            \"cv_avg_accuracy\": np.mean(fold_accuracies),\n",
    "            \"cv_avg_precision\": np.mean(fold_precisions),\n",
    "            \"cv_avg_recall\": np.mean(fold_recalls),\n",
    "            \"cv_avg_f1\": np.mean(fold_f1s),\n",
    "            \"cv_classification_report_df\": avg_report_df,\n",
    "            \"avg_training_time\": np.mean(training_times),\n",
    "            \"avg_prediction_time\": np.mean(prediction_times),\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"test_conf_matrix\": test_conf_matrix,\n",
    "            \"test_class_report\": test_class_report,\n",
    "        }\n",
    "\n",
    "    for name, result in cv_results.items():\n",
    "        print(f\"\\n{'='*70}\\n{name} | DATASET: {dataset_name}\")\n",
    "        print(f\"CV Average Accuracy     : {result['cv_avg_accuracy']:.4f}\")\n",
    "        print(f\"CV Avg Precision        : {result['cv_avg_precision']:.4f}\")\n",
    "        print(f\"CV Avg Recall           : {result['cv_avg_recall']:.4f}\")\n",
    "        print(f\"CV Avg F1-Score         : {result['cv_avg_f1']:.4f}\")\n",
    "        print(f\"Average Training Time   : {result['avg_training_time']:.4f} s\")\n",
    "        print(f\"Average Prediction Time : {result['avg_prediction_time']:.4f} s\")\n",
    "        \n",
    "        print(\"\\nAverage Classification Report from 5-Fold CV:\")\n",
    "        print(result[\"cv_classification_report_df\"])\n",
    "\n",
    "        print(f\"\\nTest Set Accuracy (20%) : {result['test_accuracy']:.4f}\")\n",
    "        print(\"Test Set Confusion Matrix:\")\n",
    "        print(result[\"test_conf_matrix\"])\n",
    "        print(\"Test Set Classification Report:\")\n",
    "        print(result[\"test_class_report\"])\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "results_url = run_cv_block(X_train1, y_train1, X_test1, y_test1, models, \"URL\")\n",
    "results_html = run_cv_block(X_train2, y_train2, X_test2, y_test2, models, \"HTML\")\n",
    "results_dom = run_cv_block(X_train3, y_train3, X_test3, y_test3, models, \"DOM\")\n",
    "results_combined = run_cv_block(X_train4, y_train4, X_test4, y_test4, models, \"COMBINED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd37e21-7fd5-4551-9c04-c8a6d09fa8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7342c24-c55e-4759-bca4-3c10ea48a8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de7c1d-9da8-45ad-a003-f5bc36bc22f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
